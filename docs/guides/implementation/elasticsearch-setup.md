# ğŸ”§ Elasticsearch ç›£æ§ç³»çµ±å¯¦ä½œæŒ‡å—

## ğŸ“‹ å¯¦ä½œæ¦‚è¿°

æœ¬æ–‡æª”æä¾› Elasticsearch ç›£æ§ç³»çµ±çš„è©³ç´°å¯¦ä½œæŒ‡å—ï¼ŒåŒ…æ‹¬è³‡æ–™åº«çµæ§‹ã€ç¨‹å¼ç¢¼çµæ§‹ã€å¯¦ä½œæ­¥é©Ÿå’Œæ¸¬è©¦æ–¹æ³•ã€‚

## ğŸ—„ï¸ ç²¾ç°¡é›™å±¤è³‡æ–™åº«æ¶æ§‹

### **Layer 1: MySQL (é…ç½®æ•¸æ“š)**

```sql
-- ES ç›£æ§é…ç½®è¡¨ (ä¿ç•™åœ¨ MySQLï¼Œæ•¸æ“šé‡å°ï¼Œä½é »è®€å¯«)
CREATE TABLE elasticsearch_monitors (
    id INT PRIMARY KEY AUTO_INCREMENT,
    name VARCHAR(100) NOT NULL,
    host VARCHAR(255) NOT NULL,
    port INT NOT NULL,
    username VARCHAR(100),
    password VARCHAR(255),
    enable_auth BOOLEAN DEFAULT FALSE,
    check_type VARCHAR(100) NOT NULL,
    interval_seconds INT DEFAULT 60,
    enable_monitor BOOLEAN DEFAULT TRUE,
    receivers JSON,
    subject VARCHAR(200),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    INDEX idx_name (name),
    INDEX idx_enable (enable_monitor)
);

-- Cron ä»»å‹™é—œè¯è¡¨
CREATE TABLE elasticsearch_cron_jobs (
    id INT PRIMARY KEY AUTO_INCREMENT,
    monitor_id INT NOT NULL,
    entry_id INT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (monitor_id) REFERENCES elasticsearch_monitors(id) ON DELETE CASCADE,
    UNIQUE KEY unique_monitor (monitor_id)
);
```

### **Layer 2: TimescaleDB (é«˜é »æ™‚é–“åºåˆ—æ•¸æ“š)**

```sql
-- ES ç›£æ§æŒ‡æ¨™æ™‚é–“åºåˆ—è¡¨ (é«˜é »å¯«å…¥ï¼Œå„ªåŒ–æŸ¥è©¢)
CREATE TABLE es_metrics (
    time TIMESTAMPTZ NOT NULL,
    monitor_id INTEGER NOT NULL,
    status TEXT NOT NULL,
    cluster_name TEXT,
    cluster_status TEXT,
    response_time BIGINT DEFAULT 0,
    cpu_usage DECIMAL(5,2) DEFAULT 0.00,
    memory_usage DECIMAL(5,2) DEFAULT 0.00,
    disk_usage DECIMAL(5,2) DEFAULT 0.00,
    node_count INTEGER DEFAULT 0,
    data_node_count INTEGER DEFAULT 0,
    query_latency BIGINT DEFAULT 0,
    indexing_rate DECIMAL(10,2) DEFAULT 0.00,
    search_rate DECIMAL(10,2) DEFAULT 0.00,
    total_indices INTEGER DEFAULT 0,
    total_documents BIGINT DEFAULT 0,
    total_size_bytes BIGINT DEFAULT 0,
    active_shards INTEGER DEFAULT 0,
    relocating_shards INTEGER DEFAULT 0,
    unassigned_shards INTEGER DEFAULT 0,
    error_message TEXT,
    warning_message TEXT,
    metadata JSONB
);

-- è½‰æ›ç‚ºæ™‚é–“åºåˆ—è¡¨
SELECT create_hypertable('es_metrics', 'time', chunk_time_interval => INTERVAL '1 day');

-- è‡ªå‹•å£“ç¸®ç­–ç•¥ (ç¯€çœç©ºé–“)
ALTER TABLE es_metrics SET (
    timescaledb.compress,
    timescaledb.compress_segmentby = 'monitor_id',
    timescaledb.compress_orderby = 'time DESC'
);
SELECT add_compression_policy('es_metrics', INTERVAL '7 days');

-- è‡ªå‹•æ¸…ç†ç­–ç•¥ (ä¿ç•™3å€‹æœˆ)
SELECT add_retention_policy('es_metrics', INTERVAL '90 days');

-- å‘Šè­¦æ­·å²è¡¨
CREATE TABLE es_alert_history (
    time TIMESTAMPTZ NOT NULL,
    monitor_id INTEGER NOT NULL,
    alert_type TEXT NOT NULL,
    severity TEXT NOT NULL,
    message TEXT NOT NULL,
    status TEXT DEFAULT 'active',
    resolved_at TIMESTAMPTZ,
    resolution_note TEXT
);

SELECT create_hypertable('es_alert_history', 'time', chunk_time_interval => INTERVAL '7 days');
SELECT add_retention_policy('es_alert_history', INTERVAL '90 days');

-- é«˜æ€§èƒ½ç´¢å¼•
CREATE INDEX idx_es_metrics_monitor_time ON es_metrics (monitor_id, time DESC);
CREATE INDEX idx_es_metrics_status ON es_metrics (status, time DESC);
CREATE INDEX idx_es_alert_monitor_time ON es_alert_history (monitor_id, time DESC);
CREATE INDEX idx_es_alert_severity ON es_alert_history (severity, time DESC);
```

### **å¯é¸ Layer 3: Redis (ç†±æ•¸æ“šç·©å­˜ - é«˜ä¸¦ç™¼æ™‚å•Ÿç”¨)**

```redis
# Redis æ•¸æ“šçµæ§‹è¨­è¨ˆ (å¯é¸ç†±æ•¸æ“šå±¤ï¼Œ1å°æ™‚å…§)

# 1. ES ç›£æ§æœ€æ–°ç‹€æ…‹ (å¯é¸)
es:latest:{monitor_id} -> JSON (TTL: 1 hour)
{
  "status": "online",
  "cluster_status": "green",
  "response_time": 120,
  "cpu_usage": 45.5,
  "last_check": "2024-09-30T12:00:00Z"
}

# 2. ES ç›£æ§ç¾¤çµ„çµ±è¨ˆ (å¯é¸)
es:stats:summary -> HASH (TTL: 1 hour)
{
  "total_monitors": 5,
  "online_monitors": 4,
  "critical_alerts": 1,
  "last_update": 1696075200
}

# æ³¨æ„ï¼šRedis å±¤ç‚ºå¯é¸æ“´å±•ï¼Œä¸»è¦æ¶æ§‹åƒ…ä¾è³´ MySQL + TimescaleDB
```

### æ¬Šé™è¡¨æ›´æ–°

```sql
-- æ–°å¢ ES ç›£æ§ç›¸é—œæ¬Šé™
INSERT INTO permissions (name, resource, action, description) VALUES
('elasticsearch:create', 'elasticsearch', 'create', 'Create Elasticsearch monitor'),
('elasticsearch:read', 'elasticsearch', 'read', 'Read Elasticsearch monitor data'),
('elasticsearch:update', 'elasticsearch', 'update', 'Update Elasticsearch monitor'),
('elasticsearch:delete', 'elasticsearch', 'delete', 'Delete Elasticsearch monitor');

-- ç‚º admin è§’è‰²æ–°å¢æ¬Šé™
INSERT INTO role_permissions (role_id, permission_id)
SELECT 1, id FROM permissions WHERE resource = 'elasticsearch';

-- ç‚º user è§’è‰²æ–°å¢è®€å–æ¬Šé™
INSERT INTO role_permissions (role_id, permission_id)
SELECT 2, id FROM permissions WHERE resource = 'elasticsearch' AND action = 'read';
```

## ğŸ“ æª”æ¡ˆçµæ§‹

```
log-detect-backend/
â”œâ”€â”€ entities/
â”‚   â””â”€â”€ elasticsearch.go          # ES ç›£æ§å¯¦é«”å®šç¾©
â”œâ”€â”€ models/
â”‚   â””â”€â”€ elasticsearch.go          # ES ç›£æ§æ¨¡å‹
â”œâ”€â”€ controller/
â”‚   â””â”€â”€ elasticsearch.go          # ES ç›£æ§æ§åˆ¶å™¨
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ elasticsearch_monitor.go  # ES ç›£æ§æœå‹™
â”‚   â”œâ”€â”€ elasticsearch_health.go   # ES å¥åº·æª¢æŸ¥
â”‚   â”œâ”€â”€ elasticsearch_alert.go    # ES å‘Šè­¦æœå‹™
â”‚   â””â”€â”€ elasticsearch_metrics.go  # ES æŒ‡æ¨™æ”¶é›†
â”œâ”€â”€ middleware/
â”‚   â””â”€â”€ elasticsearch_auth.go     # ES ç›£æ§æ¬Šé™ä¸­ä»‹è»Ÿé«”
â””â”€â”€ docs/
    â”œâ”€â”€ elasticsearch-monitoring.md
    â”œâ”€â”€ elasticsearch-api-spec.md
    â””â”€â”€ elasticsearch-implementation-guide.md
```

## ğŸ—ï¸ å¯¦é«”å®šç¾© (entities/elasticsearch.go)

```go
package entities

import (
    "time"
    "log-detect/models"
)

// ElasticsearchMonitor ESç›£æ§é…ç½®
type ElasticsearchMonitor struct {
    models.Common
    ID            int       `gorm:"primaryKey;autoIncrement" json:"id"`
    Name          string    `gorm:"type:varchar(100);not null" json:"name" form:"name"`
    Host          string    `gorm:"type:varchar(255);not null" json:"host" form:"host"`
    Port          int       `gorm:"not null" json:"port" form:"port"`
    Username      string    `gorm:"type:varchar(100)" json:"username" form:"username"`
    Password      string    `gorm:"type:varchar(255)" json:"-" form:"password"`
    EnableAuth    bool      `gorm:"default:false" json:"enable_auth" form:"enable_auth"`
    CheckType     string    `gorm:"type:varchar(100);not null" json:"check_type" form:"check_type"`
    IntervalSecs  int       `gorm:"default:60" json:"interval_seconds" form:"interval_seconds"`
    EnableMonitor bool      `gorm:"default:true" json:"enable_monitor" form:"enable_monitor"`
    Receivers     []string  `gorm:"serializer:json" json:"receivers" form:"receivers"`
    Subject       string    `gorm:"type:varchar(200)" json:"subject" form:"subject"`
}

// ESMetrics TimescaleDB æ™‚é–“åºåˆ—æ•¸æ“šçµæ§‹
type ESMetrics struct {
    Time             time.Time `json:"time"`
    MonitorID        int       `json:"monitor_id"`
    Status           string    `json:"status"`
    ClusterName      string    `json:"cluster_name"`
    ClusterStatus    string    `json:"cluster_status"`
    ResponseTime     int64     `json:"response_time"`
    CpuUsage         float64   `json:"cpu_usage"`
    MemoryUsage      float64   `json:"memory_usage"`
    DiskUsage        float64   `json:"disk_usage"`
    NodeCount        int       `json:"node_count"`
    DataNodeCount    int       `json:"data_node_count"`
    QueryLatency     int64     `json:"query_latency"`
    IndexingRate     float64   `json:"indexing_rate"`
    SearchRate       float64   `json:"search_rate"`
    TotalIndices     int       `json:"total_indices"`
    TotalDocuments   int64     `json:"total_documents"`
    TotalSizeBytes   int64     `json:"total_size_bytes"`
    ActiveShards     int       `json:"active_shards"`
    RelocatingShards int       `json:"relocating_shards"`
    UnassignedShards int       `json:"unassigned_shards"`
    ErrorMessage     string    `json:"error_message"`
    WarningMessage   string    `json:"warning_message"`
    Metadata         string    `json:"metadata"` // JSONB æ ¼å¼
}

// ESAlert TimescaleDB å‘Šè­¦æ­·å²
type ESAlert struct {
    Time           time.Time  `json:"time"`
    MonitorID      int        `json:"monitor_id"`
    AlertType      string     `json:"alert_type"`
    Severity       string     `json:"severity"`
    Message        string     `json:"message"`
    Status         string     `json:"status"`
    ResolvedAt     *time.Time `json:"resolved_at,omitempty"`
    ResolutionNote string     `json:"resolution_note"`
}

// ESCacheData å…§å­˜ç·©å­˜æ•¸æ“šçµæ§‹ (å¯é¸ Redis æ›¿ä»£)
type ESCacheData struct {
    MonitorID     int     `json:"monitor_id"`
    Status        string  `json:"status"`
    ClusterStatus string  `json:"cluster_status"`
    ResponseTime  int64   `json:"response_time"`
    CpuUsage      float64 `json:"cpu_usage"`
    LastCheck     string  `json:"last_check"`
}

// ElasticsearchCronJob ES Cronä»»å‹™è¨˜éŒ„
type ElasticsearchCronJob struct {
    models.Common
    ID        int `gorm:"primaryKey;autoIncrement" json:"id"`
    MonitorID int `gorm:"not null;uniqueIndex" json:"monitor_id"`
    EntryID   int `gorm:"not null" json:"entry_id"`
}

// è¡¨åè¨­å®š
func (ElasticsearchMonitor) TableName() string {
    return "elasticsearch_monitors"
}

// æ³¨æ„ï¼šTimescaleDB çš„è¡¨ååœ¨ CREATE TABLE èªå¥ä¸­å®šç¾©ï¼Œç„¡éœ€ TableName() æ–¹æ³•

func (ElasticsearchCronJob) TableName() string {
    return "elasticsearch_cron_jobs"
}
```

## ğŸ›ï¸ æ§åˆ¶å™¨å¯¦ä½œ (controller/elasticsearch.go)

```go
package controller

import (
    "net/http"
    "strconv"
    "log-detect/entities"
    "log-detect/services"
    "log-detect/models"

    "github.com/gin-gonic/gin"
)

type ElasticsearchController struct {
    esService    *services.ElasticsearchService
    alertService *services.ESAlertService
}

func NewElasticsearchController() *ElasticsearchController {
    return &ElasticsearchController{
        esService:    services.NewElasticsearchService(),
        alertService: services.NewESAlertService(),
    }
}

// @Summary ç²å–æ‰€æœ‰ESç›£æ§é…ç½®
// @Tags Elasticsearch
// @Accept json
// @Produce json
// @Security ApiKeyAuth
// @Param page query int false "é ç¢¼"
// @Param limit query int false "æ¯é ç­†æ•¸"
// @Success 200 {object} models.Response
// @Router /api/v1/elasticsearch/monitors [get]
func (ctrl *ElasticsearchController) GetMonitors(c *gin.Context) {
    // æª¢æŸ¥æ¬Šé™
    if !ctrl.checkPermission(c, "elasticsearch:read") {
        return
    }

    page, _ := strconv.Atoi(c.DefaultQuery("page", "1"))
    limit, _ := strconv.Atoi(c.DefaultQuery("limit", "10"))
    search := c.Query("search")
    enable := c.Query("enable")

    monitors, total, err := ctrl.esService.GetMonitors(page, limit, search, enable)
    if err != nil {
        c.JSON(http.StatusInternalServerError, models.Response{
            Code:    500,
            Message: err.Error(),
        })
        return
    }

    c.JSON(http.StatusOK, models.Response{
        Code:    200,
        Message: "Success",
        Data: gin.H{
            "monitors": monitors,
            "total":    total,
            "page":     page,
            "limit":    limit,
        },
    })
}

// @Summary æ–°å¢ESç›£æ§é…ç½®
// @Tags Elasticsearch
// @Accept json
// @Produce json
// @Security ApiKeyAuth
// @Param monitor body entities.ElasticsearchMonitor true "ç›£æ§é…ç½®"
// @Success 201 {object} models.Response
// @Router /api/v1/elasticsearch/monitors [post]
func (ctrl *ElasticsearchController) CreateMonitor(c *gin.Context) {
    if !ctrl.checkPermission(c, "elasticsearch:create") {
        return
    }

    var monitor entities.ElasticsearchMonitor
    if err := c.ShouldBindJSON(&monitor); err != nil {
        c.JSON(http.StatusBadRequest, models.Response{
            Code:    400,
            Message: "Invalid request data",
        })
        return
    }

    // é©—è­‰æ•¸æ“š
    if err := ctrl.validateMonitor(&monitor); err != nil {
        c.JSON(http.StatusBadRequest, models.Response{
            Code:    400,
            Message: err.Error(),
        })
        return
    }

    createdMonitor, err := ctrl.esService.CreateMonitor(&monitor)
    if err != nil {
        c.JSON(http.StatusInternalServerError, models.Response{
            Code:    500,
            Message: err.Error(),
        })
        return
    }

    c.JSON(http.StatusCreated, models.Response{
        Code:    201,
        Message: "Monitor created successfully",
        Data:    createdMonitor,
    })
}

// @Summary æ¸¬è©¦ESé€£æ¥
// @Tags Elasticsearch
// @Accept json
// @Produce json
// @Security ApiKeyAuth
// @Param id path int true "ç›£æ§ID"
// @Success 200 {object} models.Response
// @Router /api/v1/elasticsearch/monitors/{id}/test [post]
func (ctrl *ElasticsearchController) TestConnection(c *gin.Context) {
    if !ctrl.checkPermission(c, "elasticsearch:read") {
        return
    }

    id, err := strconv.Atoi(c.Param("id"))
    if err != nil {
        c.JSON(http.StatusBadRequest, models.Response{
            Code:    400,
            Message: "Invalid monitor ID",
        })
        return
    }

    result, err := ctrl.esService.TestConnection(id)
    if err != nil {
        c.JSON(http.StatusInternalServerError, models.Response{
            Code:    500,
            Message: err.Error(),
        })
        return
    }

    c.JSON(http.StatusOK, models.Response{
        Code:    200,
        Message: "Connection test completed",
        Data:    result,
    })
}

// æ¬Šé™æª¢æŸ¥è¼”åŠ©å‡½æ•¸
func (ctrl *ElasticsearchController) checkPermission(c *gin.Context, permission string) bool {
    // å¾ JWT middleware ç²å–ç”¨æˆ¶ä¿¡æ¯
    userID, exists := c.Get("user_id")
    if !exists {
        c.JSON(http.StatusUnauthorized, models.Response{
            Code:    401,
            Message: "Unauthorized",
        })
        return false
    }

    // æª¢æŸ¥æ¬Šé™
    authService := services.NewAuthService()
    hasPermission, err := authService.CheckUserPermission(userID.(uint), permission)
    if err != nil || !hasPermission {
        c.JSON(http.StatusForbidden, models.Response{
            Code:    403,
            Message: "Insufficient permissions",
        })
        return false
    }

    return true
}

// æ•¸æ“šé©—è­‰è¼”åŠ©å‡½æ•¸
func (ctrl *ElasticsearchController) validateMonitor(monitor *entities.ElasticsearchMonitor) error {
    if monitor.Name == "" {
        return fmt.Errorf("name is required")
    }
    if monitor.Host == "" {
        return fmt.Errorf("host is required")
    }
    if monitor.Port <= 0 || monitor.Port > 65535 {
        return fmt.Errorf("port must be between 1 and 65535")
    }
    if monitor.IntervalSecs < 30 {
        return fmt.Errorf("interval must be at least 30 seconds")
    }
    if len(monitor.Receivers) == 0 {
        return fmt.Errorf("at least one receiver is required")
    }

    return nil
}
```

## ğŸ”§ æœå‹™å±¤å¯¦ä½œ

### ES ç›£æ§æœå‹™ (services/elasticsearch_monitor.go)

```go
package services

import (
    "fmt"
    "time"
    "log-detect/entities"
    "log-detect/global"

    "gorm.io/gorm"
)

type ElasticsearchService struct {
    db *gorm.DB
}

func NewElasticsearchService() *ElasticsearchService {
    return &ElasticsearchService{
        db: global.Mysql,
    }
}

// ç²å–ç›£æ§é…ç½®åˆ—è¡¨
func (s *ElasticsearchService) GetMonitors(page, limit int, search, enable string) ([]entities.ElasticsearchMonitor, int64, error) {
    var monitors []entities.ElasticsearchMonitor
    var total int64

    query := s.db.Model(&entities.ElasticsearchMonitor{})

    // æœå°‹éæ¿¾
    if search != "" {
        query = query.Where("name LIKE ?", "%"+search+"%")
    }

    // ç‹€æ…‹éæ¿¾
    if enable != "" {
        enableBool := enable == "true"
        query = query.Where("enable_monitor = ?", enableBool)
    }

    // è¨ˆç®—ç¸½æ•¸
    if err := query.Count(&total).Error; err != nil {
        return nil, 0, err
    }

    // åˆ†é æŸ¥è©¢
    offset := (page - 1) * limit
    if err := query.Offset(offset).Limit(limit).Find(&monitors).Error; err != nil {
        return nil, 0, err
    }

    return monitors, total, nil
}

// æ–°å¢ç›£æ§é…ç½®
func (s *ElasticsearchService) CreateMonitor(monitor *entities.ElasticsearchMonitor) (*entities.ElasticsearchMonitor, error) {
    // æª¢æŸ¥åç¨±æ˜¯å¦é‡è¤‡
    var count int64
    s.db.Model(&entities.ElasticsearchMonitor{}).Where("name = ?", monitor.Name).Count(&count)
    if count > 0 {
        return nil, fmt.Errorf("monitor name already exists")
    }

    if err := s.db.Create(monitor).Error; err != nil {
        return nil, err
    }

    // å¦‚æœå•Ÿç”¨ç›£æ§ï¼Œç«‹å³å»ºç«‹ Cron ä»»å‹™
    if monitor.EnableMonitor {
        if err := s.CreateCronJob(monitor); err != nil {
            // è¨˜éŒ„éŒ¯èª¤ä½†ä¸å›æ»¾ï¼Œå…è¨±æ‰‹å‹•é‡å•Ÿ
            fmt.Printf("Failed to create cron job for monitor %d: %v\n", monitor.ID, err)
        }
    }

    return monitor, nil
}

// å»ºç«‹ Cron ä»»å‹™
func (s *ElasticsearchService) CreateCronJob(monitor *entities.ElasticsearchMonitor) error {
    cronExpr := fmt.Sprintf("@every %ds", monitor.IntervalSecs)

    entryID, err := global.Cron.AddFunc(cronExpr, func() {
        s.PerformMonitorCheck(monitor.ID)
    })
    if err != nil {
        return err
    }

    // è¨˜éŒ„ Cron ä»»å‹™é—œè¯
    cronJob := &entities.ElasticsearchCronJob{
        MonitorID: monitor.ID,
        EntryID:   int(entryID),
    }

    return s.db.Create(cronJob).Error
}

// åŸ·è¡Œç›£æ§æª¢æŸ¥
func (s *ElasticsearchService) PerformMonitorCheck(monitorID int) {
    monitor, err := s.GetMonitorByID(monitorID)
    if err != nil {
        fmt.Printf("Failed to get monitor %d: %v\n", monitorID, err)
        return
    }

    if !monitor.EnableMonitor {
        return
    }

    // åŸ·è¡Œå¥åº·æª¢æŸ¥
    healthChecker := NewESHealthChecker()
    metrics, err := healthChecker.CheckHealth(monitor)
    if err != nil {
        fmt.Printf("Health check failed for monitor %d: %v\n", monitorID, err)
        return
    }

    // å„²å­˜åˆ° TimescaleDB (æ‰¹é‡å¯«å…¥)
    batchWriter := global.TimescaleBatchWriter
    batchWriter.AddESMetric(*metrics)

    // å¯é¸ï¼šæ›´æ–°å…§å­˜ç·©å­˜
    if cacheAdapter := global.CacheAdapter; cacheAdapter != nil {
        cacheData := ESCacheData{
            MonitorID:     metrics.MonitorID,
            Status:        metrics.Status,
            ClusterStatus: metrics.ClusterStatus,
            ResponseTime:  metrics.ResponseTime,
            CpuUsage:      metrics.CpuUsage,
            LastCheck:     metrics.Time.Format(time.RFC3339),
        }
        cacheAdapter.SetESStatus(monitorID, cacheData)
    }

    // æª¢æŸ¥å‘Šè­¦æ¢ä»¶
    alertService := NewESAlertService()
    alerts := alertService.CheckAlertConditions(metrics, monitor)

    // ç™¼é€å‘Šè­¦é€šçŸ¥
    if len(alerts) > 0 {
        for _, alert := range alerts {
            if err := alertService.SendAlert(&alert, monitor); err != nil {
                fmt.Printf("Failed to send alert for monitor %d: %v\n", monitorID, err)
            }
        }
    }
}
```

### ES å¥åº·æª¢æŸ¥å™¨ (services/elasticsearch_health.go)

```go
package services

import (
    "context"
    "encoding/json"
    "fmt"
    "net/http"
    "time"
    "log-detect/entities"

    "github.com/elastic/go-elasticsearch/v8"
)

type ESHealthChecker struct{}

func NewESHealthChecker() *ESHealthChecker {
    return &ESHealthChecker{}
}

// åŸ·è¡Œ ES å¥åº·æª¢æŸ¥
func (hc *ESHealthChecker) CheckHealth(monitor *entities.ElasticsearchMonitor) (*entities.ESMetrics, error) {
    metrics := &entities.ESMetrics{
        Time:      time.Now(),
        MonitorID: monitor.ID,
    }

    // å»ºç«‹ ES å®¢æˆ¶ç«¯
    client, err := hc.createESClient(monitor)
    if err != nil {
        metrics.Status = "error"
        metrics.ErrorMessage = fmt.Sprintf("Failed to create ES client: %v", err)
        return metrics, nil
    }

    // æª¢æŸ¥é€£æ¥
    start := time.Now()
    if err := hc.checkConnection(client, metrics); err != nil {
        metrics.Status = "offline"
        metrics.ErrorMessage = err.Error()
        metrics.ResponseTime = time.Since(start).Milliseconds()
        return metrics, nil
    }
    metrics.ResponseTime = time.Since(start).Milliseconds()

    // æª¢æŸ¥é›†ç¾¤å¥åº·
    if err := hc.checkClusterHealth(client, metrics); err != nil {
        metrics.WarningMessage += fmt.Sprintf("Cluster health check failed: %v; ", err)
    }

    // æª¢æŸ¥ç¯€é»çµ±è¨ˆ
    if err := hc.checkNodeStats(client, metrics); err != nil {
        metrics.WarningMessage += fmt.Sprintf("Node stats check failed: %v; ", err)
    }

    // æª¢æŸ¥ç´¢å¼•çµ±è¨ˆ
    if err := hc.checkIndexStats(client, metrics); err != nil {
        metrics.WarningMessage += fmt.Sprintf("Index stats check failed: %v; ", err)
    }

    // åˆ¤æ–·æ•´é«”ç‹€æ…‹
    hc.determineOverallStatus(metrics)

    return metrics, nil
}

// å»ºç«‹ ES å®¢æˆ¶ç«¯
func (hc *ESHealthChecker) createESClient(monitor *entities.ElasticsearchMonitor) (*elasticsearch.Client, error) {
    cfg := elasticsearch.Config{
        Addresses: []string{fmt.Sprintf("%s:%d", monitor.Host, monitor.Port)},
    }

    if monitor.EnableAuth {
        cfg.Username = monitor.Username
        cfg.Password = monitor.Password
    }

    return elasticsearch.NewClient(cfg)
}

// æª¢æŸ¥é€£æ¥
func (hc *ESHealthChecker) checkConnection(client *elasticsearch.Client, metrics *entities.ESMetrics) error {
    ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
    defer cancel()

    res, err := client.Info(client.Info.WithContext(ctx))
    if err != nil {
        return fmt.Errorf("connection failed: %v", err)
    }
    defer res.Body.Close()

    if res.IsError() {
        return fmt.Errorf("ES returned error: %s", res.Status())
    }

    return nil
}

// æª¢æŸ¥é›†ç¾¤å¥åº·
func (hc *ESHealthChecker) checkClusterHealth(client *elasticsearch.Client, metrics *entities.ESMetrics) error {
    res, err := client.Cluster.Health()
    if err != nil {
        return err
    }
    defer res.Body.Close()

    var health map[string]interface{}
    if err := json.NewDecoder(res.Body).Decode(&health); err != nil {
        return err
    }

    if clusterName, ok := health["cluster_name"].(string); ok {
        metrics.ClusterName = clusterName
    }

    if clusterStatus, ok := health["status"].(string); ok {
        metrics.ClusterStatus = clusterStatus
    }

    if nodeCount, ok := health["number_of_nodes"].(float64); ok {
        metrics.NodeCount = int(nodeCount)
    }

    if dataNodeCount, ok := health["number_of_data_nodes"].(float64); ok {
        metrics.DataNodeCount = int(dataNodeCount)
    }

    if activeShards, ok := health["active_shards"].(float64); ok {
        metrics.ActiveShards = int(activeShards)
    }

    if relocatingShards, ok := health["relocating_shards"].(float64); ok {
        metrics.RelocatingShards = int(relocatingShards)
    }

    if unassignedShards, ok := health["unassigned_shards"].(float64); ok {
        metrics.UnassignedShards = int(unassignedShards)
    }

    return nil
}

// åˆ¤æ–·æ•´é«”ç‹€æ…‹
func (hc *ESHealthChecker) determineOverallStatus(metrics *entities.ESMetrics) {
    // é è¨­ç‚º online
    metrics.Status = "online"

    // æª¢æŸ¥åš´é‡å•é¡Œ
    if metrics.ClusterStatus == "red" {
        metrics.Status = "error"
        return
    }

    if metrics.UnassignedShards > 0 || metrics.ClusterStatus == "yellow" {
        metrics.Status = "warning"
        return
    }

    // æª¢æŸ¥æ•ˆèƒ½å•é¡Œ
    if metrics.ResponseTime > 5000 || metrics.CpuUsage > 80 || metrics.MemoryUsage > 85 {
        metrics.Status = "warning"
        return
    }
}
```

## ğŸš¨ å‘Šè­¦æœå‹™å¯¦ä½œ (services/elasticsearch_alert.go)

```go
package services

import (
    "fmt"
    "time"
    "log-detect/entities"
    "log-detect/global"
)

type ESAlertService struct {
    db *gorm.DB
}

func NewESAlertService() *ESAlertService {
    return &ESAlertService{
        db: global.Mysql,
    }
}

// æª¢æŸ¥å‘Šè­¦æ¢ä»¶
func (s *ESAlertService) CheckAlertConditions(metrics *entities.ESMetrics, monitor *entities.ElasticsearchMonitor) []entities.ESAlert {
    var alerts []entities.ESAlert
    now := time.Now()

    // é€£æ¥å¤±æ•—å‘Šè­¦
    if metrics.Status == "offline" {
        alerts = append(alerts, entities.ESAlert{
            Time:      now,
            MonitorID: monitor.ID,
            AlertType: "connection",
            Severity:  "critical",
            Message:   fmt.Sprintf("Elasticsearch connection failed: %s", metrics.ErrorMessage),
            Status:    "active",
        })
    }

    // é›†ç¾¤ç‹€æ…‹å‘Šè­¦
    if metrics.ClusterStatus == "red" {
        alerts = append(alerts, entities.ESAlert{
            Time:      now,
            MonitorID: monitor.ID,
            AlertType: "cluster",
            Severity:  "high",
            Message:   "Cluster status is RED - data may be unavailable",
            Status:    "active",
        })
    } else if metrics.ClusterStatus == "yellow" {
        alerts = append(alerts, entities.ESAlert{
            Time:      now,
            MonitorID: monitor.ID,
            AlertType: "cluster",
            Severity:  "medium",
            Message:   "Cluster status is YELLOW - some replicas are unallocated",
            Status:    "active",
        })
    }

    // æ€§èƒ½å‘Šè­¦
    if metrics.ResponseTime > 5000 {
        alerts = append(alerts, entities.ESAlert{
            Time:      now,
            MonitorID: monitor.ID,
            AlertType: "performance",
            Severity:  "medium",
            Message:   fmt.Sprintf("High response time: %dms", metrics.ResponseTime),
            Status:    "active",
        })
    }

    if metrics.CpuUsage > 80 {
        alerts = append(alerts, entities.ESAlert{
            Time:      now,
            MonitorID: monitor.ID,
            AlertType: "performance",
            Severity:  "medium",
            Message:   fmt.Sprintf("High CPU usage: %.2f%%", metrics.CpuUsage),
            Status:    "active",
        })
    }

    if metrics.DiskUsage > 90 {
        alerts = append(alerts, entities.ESAlert{
            Time:      now,
            MonitorID: monitor.ID,
            AlertType: "disk",
            Severity:  "high",
            Message:   fmt.Sprintf("High disk usage: %.2f%%", metrics.DiskUsage),
            Status:    "active",
        })
    }

    // åˆ†ç‰‡å‘Šè­¦
    if metrics.UnassignedShards > 0 {
        alerts = append(alerts, entities.ESAlert{
            Time:      now,
            MonitorID: monitor.ID,
            AlertType: "shards",
            Severity:  "medium",
            Message:   fmt.Sprintf("%d unassigned shards detected", metrics.UnassignedShards),
            Status:    "active",
        })
    }

    return alerts
}

// ç™¼é€å‘Šè­¦é€šçŸ¥
func (s *ESAlertService) SendAlert(alert *entities.ESAlert, monitor *entities.ElasticsearchMonitor) error {
    // æª¢æŸ¥æ˜¯å¦å·²ç¶“ç™¼é€éç›¸åŒå‘Šè­¦ï¼ˆé¿å…é‡è¤‡ç™¼é€ï¼‰
    if s.isDuplicateAlert(alert) {
        return nil
    }

    // å„²å­˜å‘Šè­¦è¨˜éŒ„åˆ° TimescaleDB
    batchWriter := global.TimescaleBatchWriter
    batchWriter.AddESAlert(*alert)

    // æº–å‚™éƒµä»¶å…§å®¹
    subject := fmt.Sprintf("[%s] %s", alert.Severity, monitor.Subject)
    body := s.buildAlertEmailBody(alert, monitor)

    // ç™¼é€éƒµä»¶
    return SendMail(monitor.Receivers, subject, body)
}

// æª¢æŸ¥æ˜¯å¦ç‚ºé‡è¤‡å‘Šè­¦ (æŸ¥è©¢ TimescaleDB)
func (s *ESAlertService) isDuplicateAlert(alert *entities.ESAlert) bool {
    // æŸ¥è©¢ TimescaleDB æª¢æŸ¥é‡è¤‡å‘Šè­¦
    query := `
        SELECT COUNT(*)
        FROM es_alert_history
        WHERE monitor_id = $1
            AND alert_type = $2
            AND status = 'active'
            AND time > $3
    `

    var count int64
    global.TimescaleDB.QueryRow(query,
        alert.MonitorID,
        alert.AlertType,
        time.Now().Add(-time.Hour)).Scan(&count)

    return count > 0
}

// å»ºç«‹å‘Šè­¦éƒµä»¶å…§å®¹
func (s *ESAlertService) buildAlertEmailBody(alert *entities.ESAlert, monitor *entities.ElasticsearchMonitor) string {
    return fmt.Sprintf(`
Dear Administrator,

An alert has been triggered for Elasticsearch monitor: %s

Alert Details:
- Type: %s
- Severity: %s
- Message: %s
- Time: %s
- Monitor: %s (%s:%d)

Please check your Elasticsearch cluster and take appropriate action.

Best regards,
Log Detect Monitoring System
`,
        monitor.Name,
        alert.AlertType,
        alert.Severity,
        alert.Message,
        alert.Time.Format("2006-01-02 15:04:05"),
        monitor.Name,
        monitor.Host,
        monitor.Port,
    )
}
```

## ğŸ“ˆ å¯¦ä½œæ­¥é©Ÿ

### Phase 1: åŸºç¤å»ºè¨­ (é›™å±¤æ¶æ§‹)
1. **è³‡æ–™åº«å»ºç«‹**:
   - MySQL: åŸ·è¡Œç›£æ§é…ç½®è¡¨ SQL
   - TimescaleDB: å»ºç«‹æ™‚é–“åºåˆ—è¡¨å’Œç´¢å¼•
2. **å¯¦é«”å®šç¾©**: å»ºç«‹ `entities/elasticsearch.go`
3. **åŸºæœ¬ API**: å¯¦ä½œç›£æ§é…ç½®çš„ CRUD API
4. **æ¬Šé™æ•´åˆ**: æ–°å¢æ¬Šé™å®šç¾©å’Œä¸­ä»‹è»Ÿé«”

### Phase 2: ç›£æ§æ ¸å¿ƒ (TimescaleDB é›†æˆ)
1. **å¥åº·æª¢æŸ¥å™¨**: å¯¦ä½œ ES é€£æ¥å’Œå¥åº·æª¢æŸ¥
2. **æ‰¹é‡å¯«å…¥**: æ•´åˆ TimescaleDB æ‰¹é‡å¯«å…¥æ©Ÿåˆ¶
3. **ç›£æ§æœå‹™**: å¯¦ä½œå®šæœŸç›£æ§é‚è¼¯ï¼Œæ”¯æ´é«˜é »æ•¸æ“šå¯«å…¥
4. **Cron æ•´åˆ**: å°‡ ES ç›£æ§æ•´åˆåˆ°ç¾æœ‰èª¿åº¦ç³»çµ±

### Phase 3: å‘Šè­¦ç³»çµ± (TimescaleDB å­˜å„²)
1. **å‘Šè­¦è¦å‰‡**: å¯¦ä½œå‘Šè­¦æ¢ä»¶åˆ¤æ–·
2. **å‘Šè­¦å­˜å„²**: å‘Šè­¦æ­·å²å­˜å…¥ TimescaleDB
3. **é€šçŸ¥æœå‹™**: æ•´åˆç¾æœ‰éƒµä»¶ç³»çµ±ç™¼é€å‘Šè­¦
4. **é‡è¤‡æª¢æŸ¥**: åŸºæ–¼ TimescaleDB æŸ¥è©¢é¿å…é‡è¤‡å‘Šè­¦

### Phase 4: å„€è¡¨æ¿å’Œå„ªåŒ–
1. **æŸ¥è©¢å„ªåŒ–**: å¯¦ä½œé«˜æ€§èƒ½æ™‚é–“åºåˆ—æŸ¥è©¢
2. **API å®Œå–„**: æ”¯æ´é›™å±¤æ¶æ§‹çš„æŸ¥è©¢å’Œçµ±è¨ˆ API
3. **å„€è¡¨æ¿æ•´åˆ**: åœ¨ç¾æœ‰ Dashboard ä¸­æ–°å¢ ES ç›£æ§
4. **å¯é¸æ“´å±•**: è©•ä¼°æ˜¯å¦éœ€è¦åŠ å…¥ Redis ç·©å­˜å±¤

## ğŸ§ª æ¸¬è©¦æ–¹æ³•

### å–®å…ƒæ¸¬è©¦
```go
func TestElasticsearchHealthCheck(t *testing.T) {
    // æ¸¬è©¦ ES å¥åº·æª¢æŸ¥é‚è¼¯
}

func TestAlertConditions(t *testing.T) {
    // æ¸¬è©¦å‘Šè­¦æ¢ä»¶åˆ¤æ–·
}
```

### æ•´åˆæ¸¬è©¦
```bash
# æ¸¬è©¦å®Œæ•´ç›£æ§æµç¨‹
./test_es_monitoring.sh
```

### æ‰‹å‹•æ¸¬è©¦
```bash
# å»ºç«‹æ¸¬è©¦ç›£æ§é…ç½®
curl -X POST http://localhost:8006/api/v1/elasticsearch/monitors \
  -H "Authorization: Bearer $TOKEN" \
  -d '{"name":"Test ES","host":"localhost","port":9200,...}'

# æ¸¬è©¦é€£æ¥
curl -X POST http://localhost:8006/api/v1/elasticsearch/monitors/1/test \
  -H "Authorization: Bearer $TOKEN"
```

---

**ç‰ˆæœ¬**: 1.0
**æœ€å¾Œæ›´æ–°**: 2024-09-30
**ä½œè€…**: Log Detect é–‹ç™¼åœ˜éšŠ